{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wX2Tg3T06DaKdz1vBl9R_NN1wk3OhDB5","timestamp":1717492148423},{"file_id":"1qZtMeCFCQCsF8tucQ4sH2YFdVgMPDP9J","timestamp":1714878471519},{"file_id":"19nNwoiMUoZILQrID-3efLEa-GgQooZPW","timestamp":1713839372874},{"file_id":"12cCA5UIAxGQWWYkwj3R8b6T57szkunGY","timestamp":1697782071237},{"file_id":"1vC1rSs4duwCzgLjUoM9XVkpyZD4VhvyW","timestamp":1670464331546},{"file_id":"1R77BJF9vQwCHnb2vbBAuTY8plBeTb0Aw","timestamp":1670417855748},{"file_id":"1BWIROyD9joWZv-6hk7CpytfhI7UFaaMm","timestamp":1670294241499},{"file_id":"1CN3txqHX9QtQ0JmJk2MFEALuVC6g1I8n","timestamp":1670291365246},{"file_id":"1K_ck1EBmNZQ9g48HENyGA_tH81-L5EC6","timestamp":1664325542827},{"file_id":"11UMaL-_xS6XEBQwLMWt-24UJdx33gtoE","timestamp":1655822869823},{"file_id":"1ClKrH42VxayGaV756EnnSUrxspr7GRmR","timestamp":1655779138386},{"file_id":"1zWiOD_mArP2KHvnsZ5eA8x7F5n9SmDz9","timestamp":1652361829054},{"file_id":"1wc2U1yyxFlrxSugxy9-3WFKBL0mwZwjh","timestamp":1649210953033}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import your dataset and you can start to plan on how to clean and present your data in WordCloud. Happy Coding!"],"metadata":{"id":"a7qRY64UyeoL"}},{"cell_type":"code","source":["#import pandas to view your data\n","import pandas as pd"],"metadata":{"id":"XQujEbqulM00","executionInfo":{"status":"ok","timestamp":1717510709575,"user_tz":-480,"elapsed":919,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## How to import data into Colab?\n","\n","\n"],"metadata":{"id":"o6yeUFggTCQL"}},{"cell_type":"markdown","source":["#### From colab folder\n","\n","Drag/upload your file into colab files directory."],"metadata":{"id":"0R2ei6jbFvZf"}},{"cell_type":"code","source":["import pandas as pd\n","raw_data = pd.read_csv('aliffAziz.csv')\n","\n","raw_data.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"jDx4WsitlRkS","executionInfo":{"status":"error","timestamp":1717510709575,"user_tz":-480,"elapsed":8,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"f41fae32-02e5-4f9d-a5b0-97b60fad206e"},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'aliffAziz.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2a926e30662a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aliffAziz.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aliffAziz.csv'"]}]},{"cell_type":"markdown","source":["## Prepare our data\n","You will be focusing only on Tweet column. In this example, you will create a new dataframe called **data_tweet** to store tweet from **raw_data**."],"metadata":{"id":"onV-KEznifkO"}},{"cell_type":"code","source":["data_tweet = raw_data[[\"Tweet\"]]"],"metadata":{"id":"ya9_kIYteV-E","executionInfo":{"status":"aborted","timestamp":1717510709576,"user_tz":-480,"elapsed":5,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_tweet.head(5)"],"metadata":{"id":"IEOZDJ4gJQr4","executionInfo":{"status":"aborted","timestamp":1717510709576,"user_tz":-480,"elapsed":5,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can inspact data size by using **.shape**"],"metadata":{"id":"SI0grm8Qo99A"}},{"cell_type":"code","source":["data_tweet.shape #komen here"],"metadata":{"id":"q05-eW-tvImP","executionInfo":{"status":"aborted","timestamp":1717510709576,"user_tz":-480,"elapsed":5,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import libraries for data cleaning"],"metadata":{"id":"qO5KcGNgt8Aj"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","import string\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"metadata":{"id":"lPWAjBUj3CKQ","executionInfo":{"status":"aborted","timestamp":1717510709577,"user_tz":-480,"elapsed":6,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Clean your data"],"metadata":{"id":"wopvLbW9zM1R"}},{"cell_type":"code","source":["# Convert text to lowercase and remove punctuations\n","text_lower = [t.lower() for t in raw_data[\"Tweet\"]]\n","text_remove_punct = \" \".join(text_lower).translate(str.maketrans('', '', string.punctuation))\n","\n","# Tokenize and remove stopwords\n","tokens = word_tokenize(text_remove_punct)\n","stop_words = set(stopwords.words('english'))\n","custom_stopwords = ['kalo', 'tgk', 'kat', 'nk', 'jd', 'sy', 'eh', 'mmg', 'je', 'ja', 'korg', 'yg', 'org', 'gf', 'npd', 'si', 'dgn', 'sbb', 'la', 'ni', 'lah']\n","stop_words.update(custom_stopwords)\n","result = [i for i in tokens if not i in stop_words]\n","\n","# Lemmatize the tokens\n","lemmatizer = WordNetLemmatizer()\n","lemmatized_tokens = [lemmatizer.lemmatize(word) for word in result]\n","\n","# Join the lemmatized tokens into a single string for word cloud\n","clean_text = \" \".join(lemmatized_tokens)"],"metadata":{"id":"SGzo8x8x29nB","executionInfo":{"status":"aborted","timestamp":1717510709577,"user_tz":-480,"elapsed":6,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use WordCloud to present your data (Raw and Clean Data). Describ"],"metadata":{"id":"8o4s8W3SzU2E"}},{"cell_type":"markdown","source":[],"metadata":{"id":"GrloDy9928iS"}},{"cell_type":"code","source":["from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","# Join the lemmatized tokens into a single string for word cloud\n","clean_text = \" \".join(lemmatized_tokens)\n","\n","# Plot word cloud for raw data\n","plt.figure(figsize=(12, 8))\n","wordcloud_raw = WordCloud(width=800, height=400, background_color='black', max_words=150, colormap='viridis').generate(text_lower_str)\n","plt.imshow(wordcloud_raw, interpolation=\"bilinear\")\n","plt.title('Word Cloud for Raw Data', fontsize=20)\n","plt.axis('off')\n","plt.show()\n","\n","# Plot word cloud for clean data\n","clean_text = \" \".join(lemmatized_tokens)\n","plt.figure(figsize=(12, 8))\n","wordcloud_clean = WordCloud(width=800, height=400, background_color='white', max_words=150, colormap='viridis').generate(clean_text)\n","plt.imshow(wordcloud_clean, interpolation=\"bilinear\")\n","plt.title('Word Cloud for Cleaned Data', fontsize=20)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"-yd-cw3l2_s1","executionInfo":{"status":"aborted","timestamp":1717510709577,"user_tz":-480,"elapsed":6,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Handling missing data and print cleaned data."],"metadata":{"id":"-izgc51ndiC_"}},{"cell_type":"code","source":["# Print cleaned data\n","print(\"Cleaned Data:\")\n","print(raw_data[\"Tweet\"].head(5))"],"metadata":{"id":"8pRuRf-IdoR6","executionInfo":{"status":"aborted","timestamp":1717510709578,"user_tz":-480,"elapsed":7,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}}},"execution_count":null,"outputs":[]}]}