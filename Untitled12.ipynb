{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNB3q5HCoeQlLJLGD5CFdX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!cp \"/content/drive/My Drive/Colab Notebooks/*.ipynb\" /content/GeneralGoogleColab/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prTDS5zzbS9R","executionInfo":{"status":"ok","timestamp":1746850892997,"user_tz":-480,"elapsed":108,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"3bd575fd-f8fa-4b5a-f2be-a47546b6005e"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/My Drive/Colab Notebooks/*.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":["!ls /content/GeneralGoogleColab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8bKOQoebXVg","executionInfo":{"status":"ok","timestamp":1746850907082,"user_tz":-480,"elapsed":141,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"f694d236-091a-4bf3-830c-d0eb2ce5db65"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["'A194789 A walkthrough of text analysis and TF-IDF.ipynb'\n","'A194789_LAB 9: AUTOMATE MACHINE LEARNING WORKFLOWS WITH PIPELINES.ipynb'\n","'A194789 Lab task 1 TA2023 Corpus and Text Preprocessing_1.ipynb'\n","'A194789 Lab task 2 TA2023 Corpus and Text Preprocessing_2.ipynb'\n","'A194789 TA2023 Class Activity - Text Analytic Applications: Document Classification and Clustering.ipynb'\n","'A194789 TP2043 Extract_Twitter_Data_using_Tweety_Libaray.ipynb'\n","'A194789 TP2043 How to get extra password to use Tweety.ipynb'\n","'A194789_ TP2043_Lab activity  Information Extraction_Book3.ipynb'\n","'A194789_ TP2043_Lab activity  Information Extraction_Book5.ipynb'\n","'A194789_TP2043_Lab activity  Information Extraction.ipynb'\n","'A194789 TP2043 Text_Preprocessing (Part 1).ipynb'\n"," A194789_TTTC3213_visual_data_profiling_students.ipynb\n","'Another copy of DRAFT PROJECT DEEP LEARNING.ipynb'\n"," app.ipynb\n","'assignment1-part1: pandas tutorial online.ipynb'\n","'Assignment ML Ques 1.ipynb'\n"," bLA2.ipynb\n","'CGPA Calculation.ipynb'\n","'Chapter25 ML.ipynb'\n","'Copy of DataEngineeringTask.ipynb'\n","'Copy of DeepEmotionML.ipynb'\n","'Copy of DeepEmotionNew.ipynb'\n","'Copy of DL_LAB 7 (NEW).ipynb'\n","'Copy of DRAFT PROJECT DEEP LEARNING.ipynb'\n","'Copy of GROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb'\n","'Copy of GROUP FIREFLY TASK 2:  Clean your data .ipynb'\n","'Copy of Group Firefly TP2043 3 Topic Modelling.ipynb'\n","'Copy of Intro_to_Weights_&_Biases.ipynb'\n","'Copy of LAB01.ipynb'\n","'Copy of LAB 2: Understand Your Data with Descriptive Statistics.ipynb'\n","'Copy of Perceptron-Concept.ipynb'\n","'Copy of Project  Principles of Data Science.ipynb'\n","'Copy of Sentiment_Analysis TP2043.ipynb'\n","'Copy of TC3313_Project2.ipynb'\n","'Copy of Untitled1.ipynb'\n","'CSS_scrapy_2021 (1).ipynb'\n","'CSS_scrapy_2021 (2).ipynb'\n","'CSS_scrapy_2021 (3).ipynb'\n"," CSS_scrapy_2021.ipynb\n"," CSS_scrapy_2024.ipynb\n"," DataEngineeringTask.ipynb\n","'Data Mining Lab 3 and 4.ipynb'\n"," DBSCAN.ipynb\n"," DE_Assignment_A194789.ipynb\n"," DeepEmotionML.ipynb\n"," DeepEmotionNew.ipynb\n"," DEFinal.ipynb\n"," DenseNet_Prostate_Cancer_Phython.ipynb\n","'DETest3 12.ipynb'\n"," Dev_BrandShoes_AiPrompt.ipynb\n"," Dev_BrandShoes_Review_Few-Shot_Learning.ipynb\n","'draft prj principle.ipynb'\n","'Edit of DeepEmotionML.ipynb'\n"," FakeNewsDetectionFYP2.ipynb\n"," FakeNewsDetectionFYP.ipynb\n"," FakeNewsDetectionTry.ipynb\n","'Fixing GROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb'\n"," FYP_Raw_2.ipynb\n"," FYP_Raw_3_new.ipynb\n"," FYP_Raw.ipynb\n"," GeneralGoogleColab\n"," Geoemotions_multiclass_dataset.ipynb\n"," Geoemotions_Only_new.ipynb\n","'GROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb'\n"," KnowYourData.ipynb\n"," Lab1_Data_Mining.ipynb\n"," Lab2_Data_Mining.ipynb\n","'LAB 2: Understand Your Data with Descriptive Statistics.ipynb'\n","'LAB 3: Data Visualisation.ipynb'\n","'Lab 4: Handling Noise-Binning.ipynb'\n","'Lab 5: Data Scaling.ipynb'\n","'Lab 6 A194789.ipynb'\n","'LAB 6: FEATURE SELECTION.ipynb'\n","'LAB7_A194789 (22.1-22.4 & 26.1-26.2).ipynb'\n","'LAB7_A194789 (26.1-26.2).ipynb'\n"," Lab7_Comparing_Machine_Learning_Algorithms.ipynb\n","'LAB 8: IMPROVING THE MODELS WITH ENSEMBLES.ipynb'\n","'Lab assignment 2.ipynb'\n"," lab-exe-1-1-Python_First_Code.ipynb\n"," lab-exe-1-2-loops.ipynb\n","'lab-exe-1-3-Conditions (1).ipynb'\n"," lab-exe-1-3-Conditions.ipynb\n"," lab-exe-1-4-Functions.ipynb\n","'lab_exe_2_1_Reading_Files_updated2023 (1).ipynb'\n"," lab_exe_2_1_Reading_Files_updated2023.ipynb\n"," lab_exe_2_2_Writing_and_Saving_Files.ipynb\n","'ML_LAB 7 (A194789).ipynb'\n","'ML_LAB8_(A194789).ipynb'\n"," ML_PROJECT.ipynb\n"," NLP_Chatbots.ipynb\n"," NLP_Chatbots_Testing.ipynb\n"," Perceptron-Concept.ipynb\n"," Project2.ipynb\n","'PROJECT DEEP LEARNING.ipynb'\n"," README.md\n"," scrapy_exercise_2024.ipynb\n"," Semeval_Only.ipynb\n"," Semeval_Only_new.ipynb\n"," TEC_new.ipynb\n"," TEC_Only.ipynb\n"," TEC_Only_new.ipynb\n"," TestDE.ipynb\n","'Testing (Hybrid) of NLP_Chatbots.ipynb'\n","'Testing (Rule_Based) of NLP_Chatbots.ipynb'\n"," TorchApi.ipynb\n","' TP2043 3 Topic Modelling_A194789.ipynb'\n","'TP2043 3 Topic Modelling_A194789.ipynb'\n"," TP2633_2024_CFG_Parsing.ipynb\n"," TP2633_2024_Lab_1_1_Text_Preprocessing.ipynb\n"," TP2633_2024_Lab1_2_Regular_Expressions.ipynb\n","'TP2633_2024_Lab_2_N_Grams (1).ipynb'\n"," TP2633_2024_Lab_2_N_Grams.ipynb\n","'TP2633_2024_Lab3_POS_Tagging (2) (1).ipynb'\n","'TP2633_2024_Lab3_POS_Tagging (2).ipynb'\n"," TP2633_2024_Lab_5_Text_Classification_SA_ML_Approach.ipynb\n"," TP2633_2024_Lab_6_SA_Lexicon_based_Approach.ipynb\n"," TP2633_2024_Lab_8_Named_Entity_Recognition.ipynb\n"," TP2633_Lab_7_Word_Embeddings.ipynb\n"," Train-Perceptron.ipynb\n"," TTTC3123_binning_student-2021.ipynb\n","'TTTC3213_data_wrangling_missing_data_student (1).ipynb'\n","'TTTC3213_data_wrangling_missing_data_student (2).ipynb'\n"," TTTC3213_data_wrangling_missing_data_student.ipynb\n"," Untitled0.ipynb\n"," Untitled10.ipynb\n"," Untitled11.ipynb\n"," Untitled12.ipynb\n"," Untitled1.ipynb\n"," Untitled2.ipynb\n","'Untitled3 (1).ipynb'\n"," Untitled3.ipynb\n","'Untitled4 (1).ipynb'\n"," Untitled4.ipynb\n"," Untitled5.ipynb\n"," Untitled6.ipynb\n"," Untitled7.ipynb\n"," Untitled8.ipynb\n"," Untitled9.ipynb\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmEYuAOUbZJk","executionInfo":{"status":"ok","timestamp":1746850919583,"user_tz":-480,"elapsed":311,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"1ad1e126-7023-44f3-cd06-5e2b4a420374"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["error: 'GeneralGoogleColab/' does not have a commit checked out\n","fatal: adding files failed\n"]}]},{"cell_type":"code","source":["!git commit -m \"Add Colab notebooks and README\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STvnstambegS","executionInfo":{"status":"ok","timestamp":1746850936498,"user_tz":-480,"elapsed":148,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"2239bbb4-7266-4dec-8cdd-dd211455b092"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is based on 'origin/main', but the upstream is gone.\n","  (use \"git branch --unset-upstream\" to fixup)\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31m TP2043 3 Topic Modelling_A194789.ipynb\u001b[m\n","\t\u001b[31mA194789 A walkthrough of text analysis and TF-IDF.ipynb\u001b[m\n","\t\u001b[31mA194789 Lab task 1 TA2023 Corpus and Text Preprocessing_1.ipynb\u001b[m\n","\t\u001b[31mA194789 Lab task 2 TA2023 Corpus and Text Preprocessing_2.ipynb\u001b[m\n","\t\u001b[31mA194789 TA2023 Class Activity - Text Analytic Applications: Document Classification and Clustering.ipynb\u001b[m\n","\t\u001b[31mA194789 TP2043 Extract_Twitter_Data_using_Tweety_Libaray.ipynb\u001b[m\n","\t\u001b[31mA194789 TP2043 How to get extra password to use Tweety.ipynb\u001b[m\n","\t\u001b[31mA194789 TP2043 Text_Preprocessing (Part 1).ipynb\u001b[m\n","\t\u001b[31mA194789_ TP2043_Lab activity  Information Extraction_Book3.ipynb\u001b[m\n","\t\u001b[31mA194789_ TP2043_Lab activity  Information Extraction_Book5.ipynb\u001b[m\n","\t\u001b[31mA194789_LAB 9: AUTOMATE MACHINE LEARNING WORKFLOWS WITH PIPELINES.ipynb\u001b[m\n","\t\u001b[31mA194789_TP2043_Lab activity  Information Extraction.ipynb\u001b[m\n","\t\u001b[31mA194789_TTTC3213_visual_data_profiling_students.ipynb\u001b[m\n","\t\u001b[31mAnother copy of DRAFT PROJECT DEEP LEARNING.ipynb\u001b[m\n","\t\u001b[31mAssignment ML Ques 1.ipynb\u001b[m\n","\t\u001b[31mCGPA Calculation.ipynb\u001b[m\n","\t\u001b[31mCSS_scrapy_2021 (1).ipynb\u001b[m\n","\t\u001b[31mCSS_scrapy_2021 (2).ipynb\u001b[m\n","\t\u001b[31mCSS_scrapy_2021 (3).ipynb\u001b[m\n","\t\u001b[31mCSS_scrapy_2021.ipynb\u001b[m\n","\t\u001b[31mCSS_scrapy_2024.ipynb\u001b[m\n","\t\u001b[31mChapter25 ML.ipynb\u001b[m\n","\t\u001b[31mCopy of DL_LAB 7 (NEW).ipynb\u001b[m\n","\t\u001b[31mCopy of DRAFT PROJECT DEEP LEARNING.ipynb\u001b[m\n","\t\u001b[31mCopy of DataEngineeringTask.ipynb\u001b[m\n","\t\u001b[31mCopy of DeepEmotionML.ipynb\u001b[m\n","\t\u001b[31mCopy of DeepEmotionNew.ipynb\u001b[m\n","\t\u001b[31mCopy of GROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb\u001b[m\n","\t\u001b[31mCopy of GROUP FIREFLY TASK 2:  Clean your data .ipynb\u001b[m\n","\t\u001b[31mCopy of Group Firefly TP2043 3 Topic Modelling.ipynb\u001b[m\n","\t\u001b[31mCopy of Intro_to_Weights_&_Biases.ipynb\u001b[m\n","\t\u001b[31mCopy of LAB 2: Understand Your Data with Descriptive Statistics.ipynb\u001b[m\n","\t\u001b[31mCopy of LAB01.ipynb\u001b[m\n","\t\u001b[31mCopy of Perceptron-Concept.ipynb\u001b[m\n","\t\u001b[31mCopy of Project  Principles of Data Science.ipynb\u001b[m\n","\t\u001b[31mCopy of Sentiment_Analysis TP2043.ipynb\u001b[m\n","\t\u001b[31mCopy of TC3313_Project2.ipynb\u001b[m\n","\t\u001b[31mCopy of Untitled1.ipynb\u001b[m\n","\t\u001b[31mDBSCAN.ipynb\u001b[m\n","\t\u001b[31mDEFinal.ipynb\u001b[m\n","\t\u001b[31mDETest3 12.ipynb\u001b[m\n","\t\u001b[31mDE_Assignment_A194789.ipynb\u001b[m\n","\t\u001b[31mData Mining Lab 3 and 4.ipynb\u001b[m\n","\t\u001b[31mDataEngineeringTask.ipynb\u001b[m\n","\t\u001b[31mDeepEmotionML.ipynb\u001b[m\n","\t\u001b[31mDeepEmotionNew.ipynb\u001b[m\n","\t\u001b[31mDenseNet_Prostate_Cancer_Phython.ipynb\u001b[m\n","\t\u001b[31mDev_BrandShoes_AiPrompt.ipynb\u001b[m\n","\t\u001b[31mDev_BrandShoes_Review_Few-Shot_Learning.ipynb\u001b[m\n","\t\u001b[31mEdit of DeepEmotionML.ipynb\u001b[m\n","\t\u001b[31mFYP_Raw.ipynb\u001b[m\n","\t\u001b[31mFYP_Raw_2.ipynb\u001b[m\n","\t\u001b[31mFYP_Raw_3_new.ipynb\u001b[m\n","\t\u001b[31mFakeNewsDetectionFYP.ipynb\u001b[m\n","\t\u001b[31mFakeNewsDetectionFYP2.ipynb\u001b[m\n","\t\u001b[31mFakeNewsDetectionTry.ipynb\u001b[m\n","\t\u001b[31mFixing GROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb\u001b[m\n","\t\u001b[31mGROUP FIREFLY PROJECT 1 : Social Media Text Analysis .ipynb\u001b[m\n","\t\u001b[31mGeneralGoogleColab/\u001b[m\n","\t\u001b[31mGeoemotions_Only_new.ipynb\u001b[m\n","\t\u001b[31mGeoemotions_multiclass_dataset.ipynb\u001b[m\n","\t\u001b[31mKnowYourData.ipynb\u001b[m\n","\t\u001b[31mLAB 2: Understand Your Data with Descriptive Statistics.ipynb\u001b[m\n","\t\u001b[31mLAB 3: Data Visualisation.ipynb\u001b[m\n","\t\u001b[31mLAB 6: FEATURE SELECTION.ipynb\u001b[m\n","\t\u001b[31mLAB 8: IMPROVING THE MODELS WITH ENSEMBLES.ipynb\u001b[m\n","\t\u001b[31mLAB7_A194789 (22.1-22.4 & 26.1-26.2).ipynb\u001b[m\n","\t\u001b[31mLAB7_A194789 (26.1-26.2).ipynb\u001b[m\n","\t\u001b[31mLab 4: Handling Noise-Binning.ipynb\u001b[m\n","\t\u001b[31mLab 5: Data Scaling.ipynb\u001b[m\n","\t\u001b[31mLab 6 A194789.ipynb\u001b[m\n","\t\u001b[31mLab assignment 2.ipynb\u001b[m\n","\t\u001b[31mLab1_Data_Mining.ipynb\u001b[m\n","\t\u001b[31mLab2_Data_Mining.ipynb\u001b[m\n","\t\u001b[31mLab7_Comparing_Machine_Learning_Algorithms.ipynb\u001b[m\n","\t\u001b[31mML_LAB 7 (A194789).ipynb\u001b[m\n","\t\u001b[31mML_LAB8_(A194789).ipynb\u001b[m\n","\t\u001b[31mML_PROJECT.ipynb\u001b[m\n","\t\u001b[31mNLP_Chatbots.ipynb\u001b[m\n","\t\u001b[31mNLP_Chatbots_Testing.ipynb\u001b[m\n","\t\u001b[31mPROJECT DEEP LEARNING.ipynb\u001b[m\n","\t\u001b[31mPerceptron-Concept.ipynb\u001b[m\n","\t\u001b[31mProject2.ipynb\u001b[m\n","\t\u001b[31mSemeval_Only.ipynb\u001b[m\n","\t\u001b[31mSemeval_Only_new.ipynb\u001b[m\n","\t\u001b[31mTEC_Only.ipynb\u001b[m\n","\t\u001b[31mTEC_Only_new.ipynb\u001b[m\n","\t\u001b[31mTEC_new.ipynb\u001b[m\n","\t\u001b[31mTP2043 3 Topic Modelling_A194789.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_CFG_Parsing.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab1_2_Regular_Expressions.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab3_POS_Tagging (2) (1).ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab3_POS_Tagging (2).ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_1_1_Text_Preprocessing.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_2_N_Grams (1).ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_2_N_Grams.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_5_Text_Classification_SA_ML_Approach.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_6_SA_Lexicon_based_Approach.ipynb\u001b[m\n","\t\u001b[31mTP2633_2024_Lab_8_Named_Entity_Recognition.ipynb\u001b[m\n","\t\u001b[31mTP2633_Lab_7_Word_Embeddings.ipynb\u001b[m\n","\t\u001b[31mTTTC3123_binning_student-2021.ipynb\u001b[m\n","\t\u001b[31mTTTC3213_data_wrangling_missing_data_student (1).ipynb\u001b[m\n","\t\u001b[31mTTTC3213_data_wrangling_missing_data_student (2).ipynb\u001b[m\n","\t\u001b[31mTTTC3213_data_wrangling_missing_data_student.ipynb\u001b[m\n","\t\u001b[31mTestDE.ipynb\u001b[m\n","\t\u001b[31mTesting (Hybrid) of NLP_Chatbots.ipynb\u001b[m\n","\t\u001b[31mTesting (Rule_Based) of NLP_Chatbots.ipynb\u001b[m\n","\t\u001b[31mTorchApi.ipynb\u001b[m\n","\t\u001b[31mTrain-Perceptron.ipynb\u001b[m\n","\t\u001b[31mUntitled0.ipynb\u001b[m\n","\t\u001b[31mUntitled1.ipynb\u001b[m\n","\t\u001b[31mUntitled10.ipynb\u001b[m\n","\t\u001b[31mUntitled11.ipynb\u001b[m\n","\t\u001b[31mUntitled12.ipynb\u001b[m\n","\t\u001b[31mUntitled2.ipynb\u001b[m\n","\t\u001b[31mUntitled3 (1).ipynb\u001b[m\n","\t\u001b[31mUntitled3.ipynb\u001b[m\n","\t\u001b[31mUntitled4 (1).ipynb\u001b[m\n","\t\u001b[31mUntitled4.ipynb\u001b[m\n","\t\u001b[31mUntitled5.ipynb\u001b[m\n","\t\u001b[31mUntitled6.ipynb\u001b[m\n","\t\u001b[31mUntitled7.ipynb\u001b[m\n","\t\u001b[31mUntitled8.ipynb\u001b[m\n","\t\u001b[31mUntitled9.ipynb\u001b[m\n","\t\u001b[31mapp.ipynb\u001b[m\n","\t\u001b[31massignment1-part1: pandas tutorial online.ipynb\u001b[m\n","\t\u001b[31mbLA2.ipynb\u001b[m\n","\t\u001b[31mdraft prj principle.ipynb\u001b[m\n","\t\u001b[31mlab-exe-1-1-Python_First_Code.ipynb\u001b[m\n","\t\u001b[31mlab-exe-1-2-loops.ipynb\u001b[m\n","\t\u001b[31mlab-exe-1-3-Conditions (1).ipynb\u001b[m\n","\t\u001b[31mlab-exe-1-3-Conditions.ipynb\u001b[m\n","\t\u001b[31mlab-exe-1-4-Functions.ipynb\u001b[m\n","\t\u001b[31mlab_exe_2_1_Reading_Files_updated2023 (1).ipynb\u001b[m\n","\t\u001b[31mlab_exe_2_1_Reading_Files_updated2023.ipynb\u001b[m\n","\t\u001b[31mlab_exe_2_2_Writing_and_Saving_Files.ipynb\u001b[m\n","\t\u001b[31mscrapy_exercise_2024.ipynb\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}]},{"cell_type":"code","source":["from getpass import getpass\n","token = getpass(\"Enter your GitHub token: \")\n","!git push https://AminUKM:{token}@github.com/AminUKM/GeneralGoogleColab.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBJmSYlUbrkZ","executionInfo":{"status":"ok","timestamp":1746851006703,"user_tz":-480,"elapsed":11261,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"cb087bb6-af67-40dc-b12b-0f7aff6e893f"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your GitHub token: ··········\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":["!git branch -vv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUXiuj0ocPiS","executionInfo":{"status":"ok","timestamp":1746851141390,"user_tz":-480,"elapsed":93,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"94b3ffde-0652-4f1e-ba91-42a1b2fa1cb3"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["* \u001b[32mmain\u001b[m 01e1628 [\u001b[34morigin/main\u001b[m: gone] Initialize repo with README\n"]}]},{"cell_type":"code","source":["!git branch --set-upstream-to=origin/main main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Irh-yGvLcS-s","executionInfo":{"status":"ok","timestamp":1746851155305,"user_tz":-480,"elapsed":84,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"abfb8cad-8b55-41e5-fb40-c987c4f121cd"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["error: the requested upstream branch 'origin/main' does not exist\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: If you are planning on basing your work on an upstream\u001b[m\n","\u001b[33mhint: branch that already exists at the remote, you may need to\u001b[m\n","\u001b[33mhint: run \"git fetch\" to retrieve it.\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: If you are planning to push out a new local branch that\u001b[m\n","\u001b[33mhint: will track its remote counterpart, you may want to use\u001b[m\n","\u001b[33mhint: \"git push -u\" to set the upstream config as you push.\u001b[m\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"kjRg-2PtcWAQ","executionInfo":{"status":"ok","timestamp":1746851168457,"user_tz":-480,"elapsed":273,"user":{"displayName":"MUHAMMAD AJRUL AMIN BIN MOHD ZAIDI","userId":"03324032608270041025"}},"outputId":"2ddfa1d5-7339-41bd-9eab-74bca7474ea1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["error: 'GeneralGoogleColab/' does not have a commit checked out\n","fatal: adding files failed\n"]}]}]}